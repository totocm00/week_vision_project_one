# ==========================================================
# ğŸ“¸ camera_loop ëª¨ë“ˆ
# ----------------------------------------------------------
# ê¸°ëŠ¥ ìš”ì•½:
#   - ì‹¤ì‹œê°„ìœ¼ë¡œ ì›¹ìº  í™”ë©´ì„ ë„ìš°ë©°, [SPACE] ëˆ„ë¥¼ ë•Œ OCRì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
#   - OCR ê²°ê³¼ëŠ” ë°•ìŠ¤ì™€ í…ìŠ¤íŠ¸ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ + JSON íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
#   - [q]ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.
#
# ì£¼ìš” íŠ¹ì§•:
#   âœ… í•œê¸€ ê¹¨ì§(????) ë¬¸ì œ ì™„ì „ í•´ê²° (Pillow ê¸°ë°˜ draw_korean_text ì ìš©)
#   âœ… ì„ ëª…ë„(Definition) ê³„ì‚° ë° ì‹œê° í‘œì‹œ
#   âœ… ì¹´ë©”ë¼ ìë™ ê°ì§€(auto) ì§€ì›
#   âœ… YAMLì˜ enable_* / visualize / export_options.* ì˜µì…˜ìœ¼ë¡œ
#      - ì €ì¥ ì—¬ë¶€
#      - ì‹¤ì‹œê°„ Bë°•ìŠ¤ í‘œì‹œ
#      - ì‹¤ì‹œê°„ Bë°•ìŠ¤ ì¢Œí‘œ í‘œì‹œ
#      - ë””ë²„ê·¸ìš© Bë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥
#      ë¥¼ í•œ ë²ˆì— ON/OFF ì œì–´
#
# ì‚¬ìš©ë²•:
#   1. ocr_config.yaml ì„¤ì •ê°’ì„ ì¡°ì •í•©ë‹ˆë‹¤.
#      - enable_save_output: false â†’ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì•ˆ í•¨
#      - enable_console_log: true  â†’ í„°ë¯¸ë„ì— OCR ë¡œê·¸ í‘œì‹œ
#      - visualize.draw_bbox_on_live: true  â†’ ì‹¤ì‹œê°„ í™”ë©´ì— Bë°•ìŠ¤ í‘œì‹œ
#      - visualize.show_bbox_coords_on_live: true â†’ ì‹¤ì‹œê°„ í™”ë©´ì— ì¢Œí‘œ í‘œì‹œ
#      - export_options.debug_image.enabled: true â†’ Bë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥
#   2. í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰:
#        python demos/camera_ocr_demo.py
#   3. ì‹¤í–‰ ì¤‘:
#        [SPACE] â†’ ìº¡ì²˜ ë° OCR ì‹¤í–‰
#        [q]     â†’ ì¢…ë£Œ
#
# ì‘ì„± ëª©ì :
#   - í˜„ì¥ìš© "OCR í™•ì¸ìš© ì¹´ë©”ë¼ ë°ëª¨"ë¡œ ì•ˆì •ì  í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•¨.
#   - open_vision_factoryì˜ label_text_recognition ì„œë¸Œëª¨ë“ˆ ê¸°ë°˜ ë°ëª¨.
# ==========================================================

import os
import time
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont

from label_text_recognition.config.loader import load_ocr_config
from label_text_recognition.ocr.ocr_engine import build_ocr_engines
from label_text_recognition.ocr.ocr_runner import run_ocr_on_image
from label_text_recognition.exporters.json_exporter import export_to_json
from label_text_recognition.camera.camera_initializer import init_camera


# ==========================================================
# ğŸ§© 1ï¸âƒ£ í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ í•¨ìˆ˜
# ----------------------------------------------------------
# OpenCV(cv2.putText)ëŠ” ê¸°ë³¸ í°íŠ¸ë§Œ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— í•œê¸€ì´ ê¹¨ì§‘ë‹ˆë‹¤.
# Pillow(PIL)ì„ ì´ìš©í•˜ì—¬ í•œê¸€ í°íŠ¸ë¥¼ ë¡œë“œí•˜ê³ , í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦½ë‹ˆë‹¤.
# ==========================================================
def draw_korean_text(
    img_bgr,
    text,
    x,
    y,
    font_path="/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
    font_size=20,
    color=(0, 255, 0),
):
    """
    OpenCVê°€ í•œê¸€ì„ ì§€ì›í•˜ì§€ ì•Šì•„ PILë¡œ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜.
    """
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)
    draw = ImageDraw.Draw(pil_img)

    try:
        font = ImageFont.truetype(font_path, font_size)
    except OSError:
        print("âš ï¸ NotoSans í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        font = ImageFont.load_default()

    draw.text((x, y), text, font=font, fill=color)
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)


# ==========================================================
# ğŸ§® 2ï¸âƒ£ ì„ ëª…ë„(Definition) ê³„ì‚° í•¨ìˆ˜
# ----------------------------------------------------------
# ì´ë¯¸ì§€ì˜ ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°(Laplacian Variance)ì„ ì´ìš©í•´ ì´ˆì  íë¦¼ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
# ê°’ì´ ë†’ì„ìˆ˜ë¡ ì„ ëª…í•˜ê³ , ë‚®ì„ìˆ˜ë¡ íë¦½ë‹ˆë‹¤.
# í™”ë©´ ìƒë‹¨ì˜ Definition í‘œì‹œì™€ í’ˆì§ˆ ê²½ê³  ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
# ==========================================================
def get_definition_score(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    lap = cv2.Laplacian(gray, cv2.CV_64F)
    return lap.var()


# ==========================================================
# ğŸš€ 3ï¸âƒ£ ë©”ì¸ í•¨ìˆ˜: start_camera_ocr()
# ----------------------------------------------------------
# í”„ë¡œê·¸ë¨ ì§„ì…ì .
#   [SPACE] â†’ OCR ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥
#   [q]     â†’ ì¢…ë£Œ
#
# YAML ì„¤ì •ê°’ì„ ë¶ˆëŸ¬ì™€ enable_* / visualize / export_options.* í† ê¸€ì„
# ê¸°ë°˜ìœ¼ë¡œ ê¸°ëŠ¥ì„ ì œì–´í•©ë‹ˆë‹¤.
# ----------------------------------------------------------
# ì‚¬ìš© ì˜ˆì‹œ:
#   - enable_save_output: false â†’ í´ë” ë¯¸ìƒì„± ë° ì €ì¥ ë¹„í™œì„±í™”
#   - enable_console_log: false â†’ í„°ë¯¸ë„ ë¡œê·¸ ìµœì†Œí™”
#   - visualize.draw_bbox_on_live: true â†’ ì‹¤ì‹œê°„ Bë°•ìŠ¤ ëª¨ë“œ (í…ŒìŠ¤íŠ¸ìš©)
#   - visualize.show_bbox_coords_on_live: true â†’ ì‹¤ì‹œê°„ ì¢Œí‘œ í‘œì‹œ ëª¨ë“œ (í…ŒìŠ¤íŠ¸ìš©)
# ==========================================================
def start_camera_ocr() -> None:
    """ì‹¤ì‹œê°„ ì¹´ë©”ë¼ OCR ë°ëª¨ ì‹¤í–‰"""

    # ------------------------------------------------------
    # 1ï¸âƒ£ ì„¤ì • ë¡œë“œ ë° ê¸°ë³¸ íŒŒë¼ë¯¸í„°
    # ------------------------------------------------------
    cfg = load_ocr_config()
    conf_threshold = cfg.get("conf_threshold", 0.5)
    definition_threshold = cfg.get("definition_threshold", 200)
    cls_enable = cfg.get("ocr_cls_enable", True)

    # YAML ê¸°ë°˜ ê¸°ëŠ¥ í† ê¸€ (ê¸°ì¡´)
    enable_definition_overlay = cfg.get("enable_definition_overlay", True)
    enable_console_log = cfg.get("enable_console_log", True)
    enable_save_output = cfg.get("enable_save_output", True)
    enable_retry_on_error = cfg.get("enable_retry_on_error", False)

    # ì‹œê°í™” ì˜µì…˜(visualize ì„¹ì…˜) - ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    visualize_cfg = cfg.get("visualize", {})
    show_live_preview = visualize_cfg.get("show_live_preview", True)
    draw_bbox_on_live = visualize_cfg.get("draw_bbox_on_live", False)
    show_bbox_coords_on_live = visualize_cfg.get("show_bbox_coords_on_live", False)
    # show_definition_on_live ëŠ” ê¸°ì¡´ enable_definition_overlay ì™€ í˜¸í™˜ë˜ë„ë¡ êµ¬ì„±
    show_definition_on_live = visualize_cfg.get(
        "show_definition_on_live", enable_definition_overlay
    )

    # ë””ë²„ê·¸ìš© Bë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥ ì˜µì…˜ (export_options.debug_image)
    export_options = cfg.get("export_options", {})
    debug_image_cfg = export_options.get("debug_image", {})
    debug_image_enabled = debug_image_cfg.get("enabled", False)
    debug_image_dir = debug_image_cfg.get("path", "assets/debug_images")
    debug_image_pattern = debug_image_cfg.get("filename_pattern", "debug_{ts}.png")

    # ì¶œë ¥ ê²½ë¡œ ì„¤ì • (ê¸°ì¡´ ê¸°ë³¸ ê²½ë¡œ)
    out_img_dir = cfg.get("output_dir_images", "assets/pictures")
    out_img_origin_dir = cfg.get("output_dir_images_origin", "assets/pictures-origin")
    out_json_dir = cfg.get("output_dir_json", "assets/json")

    # ì €ì¥ ê¸°ëŠ¥ì´ ì¼œì ¸ ìˆì„ ë•Œë§Œ í´ë” ìƒì„±
    if enable_save_output:
        os.makedirs(out_img_dir, exist_ok=True)
        os.makedirs(out_img_origin_dir, exist_ok=True)
        os.makedirs(out_json_dir, exist_ok=True)
        if debug_image_enabled:
            os.makedirs(debug_image_dir, exist_ok=True)
    else:
        print("ğŸ’¾ [ë¹„í™œì„±í™”] enable_save_output: false â†’ í´ë” ìƒì„±/ì €ì¥ ë¹„í™œì„±í™”")

    # ------------------------------------------------------
    # 2ï¸âƒ£ OCR ì—”ì§„ ì´ˆê¸°í™”
    # ------------------------------------------------------
    ocr_langs = cfg.get("ocr_langs", ["en"])
    ocr_engines = build_ocr_engines(ocr_langs)
    main_engine = ocr_engines[ocr_langs[0]]

    # ------------------------------------------------------
    # 3ï¸âƒ£ ì¹´ë©”ë¼ ì—´ê¸°
    # ------------------------------------------------------
    cap = init_camera(cfg)
    if cap is None:
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("âœ… Camera OCR ready")
    print("   [SPACE] â†’ OCR ì‹¤í–‰ / [q] â†’ ì¢…ë£Œ")

    font = cv2.FONT_HERSHEY_SIMPLEX

    # ì§ì „ OCR ê²°ê³¼ë¥¼ ì €ì¥í•´ë‘ëŠ” ë³€ìˆ˜
    # â†’ ì‹¤ì‹œê°„ í™”ë©´ì—ì„œ Bë°•ìŠ¤/ì¢Œí‘œë¥¼ ë‹¤ì‹œ ê·¸ë¦´ ë•Œ ì‚¬ìš©
    last_results = []
    last_def_score = 0.0

    # ------------------------------------------------------
    # 4ï¸âƒ£ ë©”ì¸ ë£¨í”„: ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬
    # ------------------------------------------------------
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            break

        # í˜„ì¬ í”„ë ˆì„ ì„ ëª…ë„ ê³„ì‚°
        live_def = get_definition_score(frame)
        display = frame.copy()

        # 4-1) í™”ë©´ ì•ˆë‚´ ë¬¸êµ¬
        cv2.putText(display, "Press [SPACE] to OCR, [q] to quit",
                    (10, 30), font, 0.6, (255, 255, 255), 2)

        # 4-2) Definition í‘œì‹œ (ì‹œê°í™” ì˜µì…˜ ê¸°ë°˜)
        if show_definition_on_live:
            color = (0, 255, 0) if live_def >= definition_threshold else (0, 0, 255)
            cv2.putText(display,
                        f"Definition: {live_def:.1f} (th={definition_threshold})",
                        (10, 60), font, 0.55, color, 2)

        # 4-3) ì‹¤ì‹œê°„ Bë°•ìŠ¤ + ì¢Œí‘œ í‘œì‹œ (í…ŒìŠ¤íŠ¸/ë””ë²„ê¹…ìš©)
        #  - last_results ëŠ” ë§ˆì§€ë§‰ìœ¼ë¡œ SPACE ëˆŒë €ì„ ë•Œì˜ OCR ê²°ê³¼ì…ë‹ˆë‹¤.
        #  - draw_bbox_on_live: Bë°•ìŠ¤ í´ë¦¬ë¼ì¸ í‘œì‹œ ì—¬ë¶€
        #  - show_bbox_coords_on_live: ê° ë°•ìŠ¤ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ ì—¬ë¶€
        if draw_bbox_on_live and last_results:
            for idx, item in enumerate(last_results):
                box = item.get("box", None)
                if not box or len(box) < 4:
                    continue

                # box: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                pts = np.array(box, dtype=np.int32).reshape((-1, 1, 2))
                cv2.polylines(display, [pts], isClosed=True, color=(0, 255, 0), thickness=2)

                if show_bbox_coords_on_live:
                    # ì¤‘ì‹¬ì  ê³„ì‚° (4ì  í‰ê· )
                    cx = int(sum(p[0] for p in box) / len(box))
                    cy = int(sum(p[1] for p in box) / len(box))

                    label = f"#{idx} ({cx}, {cy})"
                    cv2.putText(
                        display,
                        label,
                        (cx, cy - 5),
                        font,
                        0.4,
                        (0, 255, 0),
                        1,
                        cv2.LINE_AA,
                    )

        # ì¹´ë©”ë¼ í™”ë©´ í‘œì‹œ (visualize.show_live_preview)
        if show_live_preview:
            cv2.imshow("Label Text Recognition - Camera", display)
        else:
            # ì‹¤í—˜ì ìœ¼ë¡œ í™”ë©´ í‘œì‹œë¥¼ ë„ê³  ì‹¶ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜µì…˜
            # (ì—¬ê¸°ì„œëŠ” imshowë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ)
            pass

        key = cv2.waitKey(1) & 0xFF

        # ì¢…ë£Œ
        if key == ord("q"):
            break

        # --------------------------------------------------
        # ğŸŸ¢ [SPACE] ëˆ„ë¥´ë©´ OCR ì‹¤í–‰
        # --------------------------------------------------
        if key == 32:  # space
            ts = time.strftime("%Y%m%d_%H%M%S")
            print(f"\nğŸ“¸ {ts} - OCR ì‹¤í–‰ ì¤‘...")
            def_score = live_def

            # 1) OCR ìˆ˜í–‰
            results, vis_img, msg = run_ocr_on_image(
                frame.copy(), main_engine, conf_threshold, cls_enable
            )

            # 2) ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ (í† ê¸€)
            if msg.startswith("ERROR") and enable_retry_on_error:
                print("âš ï¸ OCR ì˜¤ë¥˜ ë°œìƒ â†’ 1íšŒ ì¬ì‹œë„")
                results, vis_img, msg = run_ocr_on_image(
                    frame.copy(), main_engine, conf_threshold, cls_enable
                )

            # 3) ê²°ê³¼ ì‹œê°í™” (ë°•ìŠ¤ + í…ìŠ¤íŠ¸)
            #    - vis_img ìœ„ì— Bë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³ , í•œê¸€ í…ìŠ¤íŠ¸ + ì‹ ë¢°ë„ë¥¼ í•¨ê»˜ í‘œì‹œ
            for r in results:
                box = r.get("box", [])
                text = r.get("text", "")
                avg_conf = r.get("avg_conf", 0.0)

                if box:
                    x1, y1 = int(box[0][0]), int(box[0][1])
                    x2, y2 = int(box[2][0]), int(box[2][1])
                    cv2.rectangle(vis_img, (x1, y1), (x2, y2),
                                  (0, 255, 255), 2)
                    vis_img = draw_korean_text(
                        vis_img,
                        f"{text} ({avg_conf:.2f})",
                        x1, y1 - 22,
                        font_size=20, color=(255, 0, 0)
                    )

            # ë§ˆì§€ë§‰ ê²°ê³¼ë¥¼ ì €ì¥í•´ ë‘ì—ˆë‹¤ê°€
            # ì‹¤ì‹œê°„ í™”ë©´ì—ì„œ Bë°•ìŠ¤/ì¢Œí‘œë¥¼ ë‹¤ì‹œ ê·¸ë¦´ ë•Œ ì‚¬ìš©
            last_results = results
            last_def_score = def_score

            # 4) ì €ì¥ ê²½ë¡œ ì§€ì • (ê¸°ì¡´ + JSON ê²½ë¡œ)
            img_path_origin = os.path.join(out_img_origin_dir, f"capture_{ts}.jpg")
            img_path = os.path.join(out_img_dir, f"capture_{ts}.jpg")
            json_path = os.path.join(out_json_dir, f"capture_{ts}.json")

            # 5) ì €ì¥ (enable_save_output ê¸°ë°˜)
            if enable_save_output:
                # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
                cv2.imwrite(img_path_origin, frame)
                # vis_img (Bë°•ìŠ¤ + í…ìŠ¤íŠ¸ ê·¸ë ¤ì§„ ê²°ê³¼) ì €ì¥
                cv2.imwrite(img_path, vis_img)
                # JSON ì €ì¥ (export_to_json ì€ ë‚´ë¶€ì—ì„œ config ê¸°ë°˜ export_all_json í˜¸ì¶œ)
                export_to_json(results, json_path)

                # ë””ë²„ê·¸ìš© Bë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒ ì‚¬í•­)
                if debug_image_enabled:
                    # vis_img ìœ„ì— ì¢Œí‘œ/ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€ë¡œ ê·¸ë ¤ì„œ ì €ì¥í•´ë„ ë˜ê³ ,
                    # frame ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ê·¸ë ¤ë„ ë¨. ì—¬ê¸°ì„œëŠ” vis_img ê¸°ì¤€ìœ¼ë¡œ ì €ì¥.
                    debug_frame = vis_img.copy()
                    for idx, r in enumerate(results):
                        box = r.get("box", [])
                        if not box or len(box) < 4:
                            continue
                        cx = int(sum(p[0] for p in box) / len(box))
                        cy = int(sum(p[1] for p in box) / len(box))
                        label = f"#{idx} ({cx},{cy})"
                        cv2.putText(
                            debug_frame,
                            label,
                            (cx, cy - 5),
                            font,
                            0.4,
                            (0, 255, 0),
                            1,
                            cv2.LINE_AA,
                        )

                    debug_filename = debug_image_pattern.replace("{ts}", ts)
                    debug_path = os.path.join(debug_image_dir, debug_filename)
                    cv2.imwrite(debug_path, debug_frame)
                    print(f"ğŸŸ© ë””ë²„ê·¸ Bë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥: {debug_path}")

                print(
                    "âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\n"
                    f"   - {img_path_origin}\n"
                    f"   - {img_path}\n"
                    f"   - {json_path}"
                )
            else:
                print("ğŸ’¾ ì €ì¥ ë¹„í™œì„±í™” ìƒíƒœì´ë¯€ë¡œ íŒŒì¼ì€ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # 6) ì½˜ì†” ë¡œê·¸ (enable_console_log)
            if not results:
                if enable_console_log:
                    print(f"âš ï¸ OCR ê²°ê³¼ ì—†ìŒ. Definition={def_score:.2f}")
                continue

            confs = [r.get("avg_conf", 0.0) for r in results]
            overall_conf = sum(confs) / len(confs)

            if enable_console_log:
                for r in results:
                    print(f"- {r.get('text', '')} ({r.get('avg_conf', 0.0):.2f})")
                print(f"ğŸ“ˆ í‰ê·  ì‹ ë¢°ë„: {overall_conf:.2f}")

                if def_score < definition_threshold:
                    print("âš ï¸ ì´ë¯¸ì§€ê°€ ë‹¤ì†Œ íë¦½ë‹ˆë‹¤.")
                elif overall_conf < conf_threshold:
                    print("âš ï¸ ì¸ì‹ì€ ë˜ì—ˆìœ¼ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
                else:
                    print("âœ… ì„ ëª…ë„ì™€ ì¸ì‹ë¥  ëª¨ë‘ ì–‘í˜¸í•©ë‹ˆë‹¤.")

    # ------------------------------------------------------
    # 5ï¸âƒ£ ì¢…ë£Œ ì²˜ë¦¬
    # ------------------------------------------------------
    cap.release()
    cv2.destroyAllWindows()
    print("ğŸŸ¢ OCR ì„¸ì…˜ì„ ì •ìƒ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")